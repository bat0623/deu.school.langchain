# -*- coding:utf-8 -*-
import os
import re
import sys
import time
import itertools
import pandas as pd
from glob import glob
from typing import List
from dotenv import load_dotenv
from langchain.schema import Document
from langchain.vectorstores import FAISS
from langchain import OpenAI, PromptTemplate
from langchain.agents import create_csv_agent
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import CSVLoader
from langchain.embeddings.openai import OpenAIEmbeddings

path = os.path.dirname(os.path.abspath(__file__))
SCR_PATH = os.path.abspath(__file__)
SCR_DIR, SCR_BN = os.path.split(SCR_PATH)
REPO_DIR = os.path.abspath(SCR_DIR + "/..")
ASSETS_DIR = os.path.abspath(REPO_DIR + "/static")
csv_list = glob(ASSETS_DIR + "/*.csv")

templates = {
    "case1": """'{input_text}'ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì€ '{output_text}'ì…ë‹ˆë‹¤. ì´ë¥¼ ì•ˆë‚´í•˜ë“¯ì´ ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. ëŒ€ë‹µí•  ë•ŒëŠ” ì¤„ì„ë§ì„ ì“°ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. """,
    "case2": """ChatGPT ëª¨ë¸ì„ ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”.
1. ëŒ€ë‹µì„ í•  ë•ŒëŠ” ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
2. ëŒ€ë‹µì„ í•  ë•ŒëŠ” ì•ˆë‚´í•˜ë“¯ì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
3. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì•¼í•©ë‹ˆë‹¤.
4. ë‹¹ì‹ ì€ ë™ì˜ëŒ€í•™êµì— ëŒ€í•œ ì •ë³´ë§Œ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
5. 'í•˜ì§€ë§Œ'ê³¼ ê°™ì€ ëŒ€ë‹µì„ í•´ì„œëŠ” ì•ˆë©ë‹ˆë‹¤.
6. ëª¨ë“  ëŒ€ë‹µì—ì„œëŠ” ì¶œì²˜ë¥¼ ë‚¨ê²¨ì¤˜ì•¼í•©ë‹ˆë‹¤.
---
'{input_text}'ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì€ '{output_text}'ì…ë‹ˆë‹¤.""",
}

try:
    load_dotenv()
    apikey = os.environ["OPENAI_API_KEY"]
except:
    print("Please, export your OpenAI API KEY over 'OPENAI_API_KEY' environment variable")
    print("You may create the key here: https://platform.openai.com/account/api-keys")
    sys.exit(1)


def slow_print(text):
    count = 0
    for char in text:
        print(char, end="", flush=True)
        if char in [".", "?"]:
            time.sleep(0.5)
        elif count % 5 == 0:
            time.sleep(0.2)
        else:
            time.sleep(0.05)
        count += 1
    print()


def sum_dataframe_lengths(df):
    total_length = 0
    for column in df.columns:
        column_length = df[column].astype(str).apply(len).sum()
        total_length += column_length
    return total_length


def csv_parser(query, filePath):
    df = pd.read_csv(filePath)
    if sum_dataframe_lengths(df) > 1000:
        llm = ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo-16k", max_tokens=9000)
    else:
        llm = OpenAI(temperature=0, model_name="text-davinci-003")
    try:
        agent = create_csv_agent(llm, filePath, verbose=True, kwargs={"max_iterations": 3})
        res = agent.run(query)
        return res
    except Exception as e:
        print(e)
        return "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


def load_files(query) -> List[Document]:
    embeddings = OpenAIEmbeddings()
    docs = [
        CSVLoader(file, csv_args={"delimiter": ",", "quotechar": '"'}).load()
        for file in filter(lambda x: x.endswith("menual.csv"), csv_list)
    ]
    docs = list(itertools.chain(*docs))
    db = FAISS.from_documents(docs, embeddings)
    retriever = db.as_retriever(search_kwargs={"k": 1})
    docs = retriever.get_relevant_documents(query)
    return docs


slow_print("ë™ì˜ëŒ€í•™êµ í•™ì‚¬ ì •ë³´ ì‹œìŠ¤í…œ ì±—ë´‡ DEU GPTì…ë‹ˆë‹¤.\në¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹œë‚˜ìš”? (ì¢…ë£Œë¥¼ í•˜ë ¤ë©´, 0 ì…ë ¥)")
while True:
    query = input(":")
    time.sleep(1)
    if query == "0":
        slow_print("ë‹¤ìŒì— ë˜ ë§Œë‚˜ìš”ğŸ˜€")
        sys.exit(0)
    elif len(query) == 0:
        slow_print("ì•„ë¬´ê²ƒë„ ê¶ê¸ˆí•˜ì§€ ì•Šìœ¼ì‹ ê°€ë´ìš”?")
        continue
    elif len(query) == 100:
        slow_print("100ì ì´ë‚´ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
        continue
    slow_print("ì°¾ëŠ” ì¤‘...")
    res = load_files(query)
    if len(res) > 0:
        pattern = r"filename: (\S+\.csv)"
        match = re.search(pattern, res[0].page_content.split("\n")[0])
        fileName = match.group(1)
        res = csv_parser(query=query, filePath=(ASSETS_DIR + "/" + fileName))
        prompt = PromptTemplate(
            input_variables=["input_text", "output_text"],
            template=templates["case2"],
        )
        texts = prompt.format_prompt(input_text=query, output_text=res)
        model = OpenAI(model_name="text-davinci-003", temperature=0.0)
        result = model(texts.to_string())
        slow_print(result)
    else:
        slow_print("í˜„ì¬ ì €ì—ê²ŒëŠ” ê´€ë ¨ëœ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.ğŸ˜­\ní•´ë‹¹ ë‚´ìš©ì€ ì—…ë°ì´íŠ¸ í•  ìˆ˜ ìˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.")
